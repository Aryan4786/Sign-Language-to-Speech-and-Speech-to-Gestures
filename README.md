# Indian Sign-Language-to-Speech-and-Speech-to-Indian-Sign-Gestures
In this project we used ANN (Artificial Neural Network) for creating the model and CNN (Convolutional Neural Network) on top of it for extracting the data from the images given as input.We also used various Image Processing Techniques like Gaussian Filtering and Thresholding. We also used various Pythotn modules like gTTS (Google text to Speech), numpy, Tensorflow, Textblob (for text autocorrection), cv2 (for image processing), speech_recognition (for recognising the input speech) etc.
Motivation:                                                                                                                                                                 
To develop an application which could be used by especially abled person to be able to convey their hand sign or gesture language into speech and aid an ordinary person to translate speech to gesture or hand sign language in order to make the communication more fluent between a person with hearing impairment or speaking disability but has knowledge about Indian sign language. Most of the people are not able to communicate due to either the lack of knowledge of sign language to other peoples. With this as a translator an ordinary person can also be able to transform their speech into sign language which may be understood by person who has hearing impairment. Most of the programs present usually have only American sign language as their region of processing, but this application is specially designed for Indian Sign Language (ISL) Translation.

Requirements(pip install them):

opencv tensorflow scipy numpy gTTS tKinter speech_recognition pyAudio matplotlib
